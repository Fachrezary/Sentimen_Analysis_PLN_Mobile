# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1IAzOKuRmDfBPGwrpCQUF8q7Our2aKkit

# **Proyek Analisis Sentimen - Fachreza Riyanda**
"""

# Import Library
import tweepy as tw
import pandas as pd
import os

# Menggunakan token dari twitter
consumer_key= '2kAfWmPvy5nPcoTOoRoIqSaIM'
consumer_secret= 'hkA4WAIWqS59s30QfMrj0EKJzHVf2bjBdif1HZM5DE6iUkaSX7'
access_token='1539625531591004163-IuSh4LkDgd9wXmyaPvuosVBKUslKv5'
access_token_secret='96bkZCGovhBLmLSVlu48Nlsj5xSp7rSQtvMwRggcopxLf'
bearer_token = 'YOUR_BEARER_TOKEN'  # gunakan Bearer Token untuk API v2

# Autentikasi menggunakan bearer token
client = tw.Client(bearer_token=bearer_token, wait_on_rate_limit=True)

# Menentukan query
search_words = "aplikasi pln mobile -is:retweet"
query_params = {
    'query': search_words,
    'tweet.fields': 'created_at,text',
    'max_results': 100  # nilai maksimum per permintaan adalah 100
}

users_locs = []
try:
    response = client.search_recent_tweets(**query_params)
    for tweet in response.data:
        users_locs.append([tweet.created_at, tweet.text])
except Exception as e:
    print(f"Error occurred: {e}")

tweet_text = pd.DataFrame(data=users_locs,
                          columns=["Tanggal", "Tweet Id", "Teks", "Username"])

tweet_text.to_csv('plnmobile.csv', index=False)

import pandas as pd
df= pd.read_csv('/content/plnmobile.csv')
df.head()

df.shape

df.info()

df.dtypes

import re

# Fungsi untuk membersihkan teks
def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # Menghapus URL
    text = re.sub(r'@\w+', '', text)  # Menghapus mentions
    text = re.sub(r'#\w+', '', text)  # Menghapus hashtags
    text = re.sub(r'[^\w\s]', '', text)  # Menghapus tanda baca
    text = re.sub(r'\d+', '', text)  # Menghapus angka
    text = text.lower()  # Mengubah teks ke huruf kecil
    return text

# Membersihkan teks dalam dataset
df['cleaned_text'] = df['Teks'].apply(clean_text)

# Melihat hasilnya
df[['Teks', 'cleaned_text']].head()

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import numpy as np

# Contoh fungsi pelabelan sederhana (dapat diganti dengan anotasi manual jika tersedia)
def label_sentiment(text):
    if "tidak" in text or "kurang" in text or "buruk" in text:
        return "negatif"
    elif "baik" in text or "bagus" in text or "puas" in text:
        return "positif"
    else:
        return "netral"

# Melabeli data
df['label'] = df['cleaned_text'].apply(label_sentiment)

# Tokenisasi menggunakan CountVectorizer
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(df['cleaned_text'])
y = df['label']

# Memisahkan data menjadi training set dan testing set
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Melatih model Logistic Regression
model = LogisticRegression()
model.fit(X_train, y_train)

# Memprediksi hasil pada testing set
y_pred = model.predict(X_test)

# Mengukur akurasi model
accuracy = accuracy_score(y_test, y_pred)
print(f'Akurasi model: {accuracy * 100:.2f}%')

# Melihat distribusi label
df['label'].value_counts()

from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_extraction.text import TfidfVectorizer

# Menggunakan TF-IDF untuk ekstraksi fitur
tfidf_vectorizer = TfidfVectorizer()
X_tfidf = tfidf_vectorizer.fit_transform(df['cleaned_text'])

# Memisahkan data menjadi training set dan testing set
X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)

# Melatih model Random Forest
rf_model = RandomForestClassifier()
rf_model.fit(X_train_tfidf, y_train)

# Memprediksi hasil pada testing set
y_pred_tfidf = rf_model.predict(X_test_tfidf)

# Mengukur akurasi model
accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)
print(f'Akurasi model Random Forest dengan TF-IDF: {accuracy_tfidf * 100:.2f}%')

from sklearn.svm import SVC

# Melatih model SVM
svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train_tfidf, y_train)

# Memprediksi hasil pada testing set
y_pred_svm = svm_model.predict(X_test_tfidf)

# Mengukur akurasi model
accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f'Akurasi model SVM dengan TF-IDF: {accuracy_svm * 100:.2f}%')